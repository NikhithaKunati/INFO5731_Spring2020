{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of In-class-exercise-04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikhithaKunati/INFO5731_Spring2020/blob/master/Copy_of_In_class_exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuX00KHNeSpw",
        "colab_type": "text"
      },
      "source": [
        "# **The fourth in-class-exercise**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vTOb03hG1f",
        "colab_type": "text"
      },
      "source": [
        "# 1. Text Data Preprocessing\n",
        "\n",
        "Here is a [legal case](https://github.com/unt-iialab/INFO5731_Spring2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "## 1.1 Basic feature extraction using text data\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "## 1.2 Basic Text Pre-processing of text data\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "## 1.3 Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above.\n",
        "\n",
        "\n",
        "## 1.4 Advance Text Processing\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 2-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-DWrPmHRWlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9150fdcb-5d39-40a9-945d-35eac2bf850e"
      },
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "\n",
        "data_file=\"https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\"\n",
        "data=pd.read_csv(data_file,error_bad_lines=False,names=['sentence'])\n",
        "print(\"number of sentences: \",len(data['sentence']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of sentences:  148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH1qeB59vSMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c4d88428-0149-4fc8-83b4-b3bcb6cec927"
      },
      "source": [
        "#number of word\n",
        "import pandas as pd\n",
        "data_url=\"https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\"\n",
        "data = pd.read_csv(data_url,error_bad_lines=False,names=['sentence'])\n",
        "sentence=data[\"sentence\"] != \"\"\n",
        "data=data[sentence]\n",
        "data['word_count'] = data['sentence'].apply(lambda x: len(str(x).split(\" \")))\n",
        "data[['sentence','word_count']].head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  word_count\n",
              "0                 5 Ala. 740           3\n",
              "1  Supreme Court of Alabama.           4\n",
              "2                      ADAMS           1\n",
              "3                         v.           1\n",
              "4         TANNER AND HORTON.           3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEYj8ud4vf_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b8ec5b34-94cf-4d7e-9ad4-4d5b56f81245"
      },
      "source": [
        "#number of Characters\n",
        "data['char_count'] = data['sentence'].str.len()\n",
        "data[['sentence','char_count']].head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  char_count\n",
              "0                 5 Ala. 740          10\n",
              "1  Supreme Court of Alabama.          25\n",
              "2                      ADAMS           5\n",
              "3                         v.           2\n",
              "4         TANNER AND HORTON.          18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAB6BUbkvkhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7bd393fb-ab38-4578-da70-60099049bb6d"
      },
      "source": [
        "#avg words count\n",
        "def avg_word(sentence):\n",
        "    words=sentence.split()\n",
        "    if len(words) !=0:\n",
        "      return(sum(len(word) for word in words)/len(words))\n",
        "    else:\n",
        "      return 0\n",
        "data['avg_word']=data['sentence'].apply(lambda x: avg_word(x))\n",
        "data[['sentence','avg_word']].head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>avg_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>5.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  avg_word\n",
              "0                 5 Ala. 740  2.666667\n",
              "1  Supreme Court of Alabama.  5.500000\n",
              "2                      ADAMS  5.000000\n",
              "3                         v.  2.000000\n",
              "4         TANNER AND HORTON.  5.333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZhCwTtkvvYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "494261e9-eed4-4d1e-b231-b04ecd780a6e"
      },
      "source": [
        "#number of stop words\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "data['stopwords'] = data['sentence'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
        "data[['sentence','stopwords']].head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  stopwords\n",
              "0                 5 Ala. 740          0\n",
              "1  Supreme Court of Alabama.          1\n",
              "2                      ADAMS          0\n",
              "3                         v.          0\n",
              "4         TANNER AND HORTON.          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrmRiTT0v5xO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "76def4e8-bb21-46a9-b569-fa20cbaa8332"
      },
      "source": [
        "#number of special characters\n",
        "\n",
        "data['specialchar']=data['sentence'].apply(lambda x: len([x for x in x.split() if x.startswith(('#','@'))]))\n",
        "data[['sentence','specialchar']].head()\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>specialchar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  specialchar\n",
              "0                 5 Ala. 740            0\n",
              "1  Supreme Court of Alabama.            0\n",
              "2                      ADAMS            0\n",
              "3                         v.            0\n",
              "4         TANNER AND HORTON.            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8QpNEFEwB6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bf5064ac-ab13-49cd-9c18-d5c925ab0fdf"
      },
      "source": [
        "#number of numerics\n",
        "data['numerics'] = data['sentence'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "data[['sentence','numerics']].head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>numerics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  numerics\n",
              "0                 5 Ala. 740         2\n",
              "1  Supreme Court of Alabama.         0\n",
              "2                      ADAMS         0\n",
              "3                         v.         0\n",
              "4         TANNER AND HORTON.         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTvcsU3vwJI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f47c9ed0-2f63-4c0a-8c0d-14ce00391b16"
      },
      "source": [
        "#number of uppercase words\n",
        "data['upper'] = data['sentence'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "data[['sentence','upper']].head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>upper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  upper\n",
              "0                 5 Ala. 740      0\n",
              "1  Supreme Court of Alabama.      0\n",
              "2                      ADAMS      1\n",
              "3                         v.      0\n",
              "4         TANNER AND HORTON.      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6jre62mwrFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6fdbe328-4bec-4a56-95bb-fac2349c3a7e"
      },
      "source": [
        "#Lower casing\n",
        "data['sentence']=data['sentence'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "data['sentence'].head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   5 ala. 740\n",
              "1    supreme court of alabama.\n",
              "2                        adams\n",
              "3                           v.\n",
              "4           tanner and horton.\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksiBAI-3wvNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0c4afb1-19e7-41af-9c62-1a72f2dfeb38"
      },
      "source": [
        "#Removing Punctuation\n",
        "\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "no_punct = \"\"\n",
        "for char in data['sentence']:\n",
        "   if char not in punctuations:\n",
        "       no_punct = no_punct + char + \"\\n\"\n",
        "\n",
        "print(no_punct)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 ala 740\n",
            "supreme court of alabama\n",
            "adams\n",
            "v\n",
            "tanner and horton\n",
            "june term\n",
            "synopsis\n",
            "writ of error to the circuit court of sumter\n",
            "west headnotes 2\n",
            "1\n",
            "chattel mortgages\n",
            "crops\n",
            "a growing crop has such an existence as to be the subjectmatter of a mortgage or other contract which passes an interest to vest in possession\n",
            "4 cases that cite this headnote\n",
            "2\n",
            "creditors’ remedies\n",
            "lien and priority\n",
            "under st1821\n",
            "5 cases that cite this headnote\n",
            "1 this was a trial of the right of property under the statute in november\n",
            "the court charged the jury\n",
            "attorneys and law firms\n",
            "r h smith\n",
            "w m murphy\n",
            "2 the lien of an execution is destroyed by an injunction\n",
            "it is admitted that the contract between the defendant in execution\n",
            "opinion\n",
            "collier\n",
            "there can be no doubt that a growing crop has such an existence as to be the subject matter of a sale\n",
            "we will then consider the writing under which the claimants assert a right\n",
            "the claimants had previous to the levy of the execution taken possession of the crop\n",
            "3 this brings us back to the question\n",
            "4 the right to levy an execution on a planted crop\n",
            "the circuit judge may have mistaken the law in supposing that the contract was a sale\n",
            "it results from what has been said\n",
            "dissenting opinion\n",
            "ormond\n",
            "4 the statute which presents the question before the court is\n",
            "i shall not enter upon the enquiry\n",
            "this act must be considered in connection with the other acts upon the same subject the policy of the state\n",
            "5 if further confirmation of the correctness of this view were necessary\n",
            "all citations\n",
            "5 ala 740\n",
            "end of document\n",
            "© 2019 thomson reuters no claim to original us government works\n",
            "citing references 9\n",
            "treatment\n",
            "title\n",
            "date\n",
            "type\n",
            "depth\n",
            "headnotes\n",
            "cited by\n",
            "1 booker v jones’s adm’x\n",
            "55 ala 266\n",
            "trover for conversion of cotton\n",
            "dec term 1876\n",
            "case\n",
            "—\n",
            "cited by\n",
            "2 lehman\n",
            "47 ala 362\n",
            "trover for conversion of cotton appeal from the city court of montgomery tried before hon john d cunningham\n",
            "jan term 1872\n",
            "case\n",
            "—\n",
            "cited by\n",
            "3 bibb v janney\n",
            "45 ala 329\n",
            "garnishment wages waiver of exemption appeal from city court of montgomery tried before hon john d cunningham\n",
            "jan term 1871\n",
            "case\n",
            "—\n",
            "cited by\n",
            "4 mckenzie v lampley\n",
            "31 ala 526\n",
            "trial of right of property in cotton appeal from the circuit court of barbour tried before the hon s d hale\n",
            "jan term 1858\n",
            "case\n",
            "—\n",
            "cited by\n",
            "5 evans v lamar\n",
            "21 ala 333\n",
            "error to the circuit court of autauga tried before the hon a b moore\n",
            "jun term 1852\n",
            "case\n",
            "—\n",
            "cited by\n",
            "6 dewey v bowman\n",
            "8 cal 145\n",
            "the judgment of the court below\n",
            "jul term 1857\n",
            "case\n",
            "—\n",
            "mentioned by\n",
            "7 rees v coats\n",
            "65 ala 256\n",
            "trover for conversion of three bales of cotton appeal from the circuit court of etowah tried before the hon wm l whitlock\n",
            "nov term 1880\n",
            "case\n",
            "—\n",
            "mentioned by\n",
            "8 edwards v thompson\n",
            "4 sw 913\n",
            "appeal from circuit court\n",
            "may 1887\n",
            "case\n",
            "—\n",
            "—\n",
            "9 growing crops as subject to levy and seizure under attachment or execution\n",
            "103 alr 464\n",
            "generally\n",
            "1936\n",
            "alr\n",
            "—\n",
            "—\n",
            "table of authorities 3\n",
            "treatment\n",
            "referenced title\n",
            "type\n",
            "depth\n",
            "quoted\n",
            "page number\n",
            "mentioned\n",
            "1 austin v sawyer\n",
            "9 cow 39\n",
            "parol evidence is not admissible to contradict\n",
            "case\n",
            "2\n",
            "cited\n",
            "2 perkins v mayfield\n",
            "5 port 182\n",
            "on writ of error to the circuit court of tuskaloosa\n",
            "case\n",
            "2\n",
            "mentioned\n",
            "3 stewart v doughty\n",
            "9 johns 108\n",
            "a let to b a farm for six years\n",
            "case\n",
            "2\n",
            "filings\n",
            "there are no filings for this citation\n",
            "negative treatment\n",
            "there are no negative treatment results for this citation\n",
            "history\n",
            "there are no history results for this citation\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiaDMBDLw0tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "023b9b06-f44e-4d18-b88c-f953c3c70d3f"
      },
      "source": [
        "#Removing Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words('english')\n",
        "data['sentence']=data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
        "data['sentence'].head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                5 ala 740\n",
              "1    supreme court alabama\n",
              "2                    adams\n",
              "3                        v\n",
              "4            tanner horton\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLX57azKw4Rn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "deda69ab-239b-4dfb-9bf1-c62e441e747d"
      },
      "source": [
        "#frequent word removal\n",
        "freq = pd.Series(' '.join(data['sentence']).split()).value_counts()[:10]\n",
        "freq\n",
        "\n",
        "freq=list(freq.index)\n",
        "data['sentence'] = data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in freq))\n",
        "data['sentence'].head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                740\n",
              "1    supreme alabama\n",
              "2              adams\n",
              "3                   \n",
              "4      tanner horton\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWC2RrATw7q8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1b904e75-1d6a-4cfb-ea9e-9e21988d085a"
      },
      "source": [
        "#rare word removal\n",
        "freq=pd.Series(' '.join(data['sentence']).split()).value_counts()[-10:]\n",
        "freq=list(freq.index)\n",
        "data['sentence']=data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in freq))\n",
        "data['sentence'].head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                740\n",
              "1    supreme alabama\n",
              "2              adams\n",
              "3                   \n",
              "4      tanner horton\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7FI_1hnw-_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c3b91485-9cec-49b4-db33-d99e7f2479e0"
      },
      "source": [
        "#spelling correcting\n",
        "freq=pd.Series(' '.join(data['sentence']).split()).value_counts()[-10:]\n",
        "freq=list(freq.index)\n",
        "data['sentence']=data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in freq))\n",
        "data['sentence'].head()\n",
        "\n",
        "from textblob import TextBlob\n",
        "data['sentence'][:5].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                740\n",
              "1    supreme alabama\n",
              "2              adams\n",
              "3                   \n",
              "4      manner norton\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGaFurUO8G-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d9283548-3e41-40ad-a469-455025215a77"
      },
      "source": [
        "#tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "TextBlob(data['sentence'][1]).words"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['supreme', 'alabama'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2wuHGfJxEjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e106698c-2e56-43d4-d29c-e1be3ba3bf17"
      },
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "data['sentence'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "data['sentence'].head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                740\n",
              "1    supreme alabama\n",
              "2              adams\n",
              "3                   \n",
              "4      manner norton\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSXoUR9ExIhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ecaff21e-feb8-443c-e53e-f09c954602eb"
      },
      "source": [
        "#Lemmetization\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "data['sentence']=data['sentence'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "data['sentence'].head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                740\n",
              "1    supreme alabama\n",
              "2               adam\n",
              "3                   \n",
              "4      manner norton\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C72lNZfoxPMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving to .csv file\n",
        "data['sentence'].to_csv(\"sentences.txt\",header=False,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnf35q3DxW43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3030f552-60cf-4d6f-817c-499fe466fbd9"
      },
      "source": [
        "#term frequency\n",
        "tf1=(data['sentence'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis=0).reset_index()\n",
        "tf1.columns=['word','tf']\n",
        "print(tf1)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       word  tf\n",
            "0   Supreme   1\n",
            "1     Court   1\n",
            "2        of   1\n",
            "3  Alabama.   1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3D5ZHD_hmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f8b2f6dc-9295-4de9-f1c2-fd4481abefca"
      },
      "source": [
        "#1-gram features\n",
        "TextBlob(data['sentence'][1]).ngrams(1)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Supreme']),\n",
              " WordList(['Court']),\n",
              " WordList(['of']),\n",
              " WordList(['Alabama'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svf78gYH_h6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "198393ca-68c6-48c8-8dc4-bddc6c0da15f"
      },
      "source": [
        "#2-gram features\n",
        "TextBlob(data['sentence'][1]).ngrams(2)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Supreme', 'Court']),\n",
              " WordList(['Court', 'of']),\n",
              " WordList(['of', 'Alabama'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSHaOTEI_ih4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60a26500-7923-4f46-f428-512369c13dce"
      },
      "source": [
        "#3-gram features\n",
        "TextBlob(data['sentence'][1]).ngrams(3)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Supreme', 'Court', 'of']), WordList(['Court', 'of', 'Alabama'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBiC4E_kefvV",
        "colab_type": "text"
      },
      "source": [
        "# 2. Python Regular Expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1QJ-UwCenvN",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Write a Python program to remove leading zeros from an IP address. \n",
        "\n",
        "ip = \"260.08.094.109\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSv6fVhOfFmv",
        "colab_type": "code",
        "outputId": "79ba0e75-5886-4b81-e937-059283f38cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Write your code here\n",
        "import re\n",
        "ip = \"260.08.094.109\"\n",
        "string = re.sub('\\.[0]*', '.', ip)\n",
        "print(string)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260.8.94.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXRjaHzrfKAy",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Write a Python Program to extract all the years from the following sentence.\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdJpDx9gjbX",
        "colab_type": "code",
        "outputId": "536d2682-d146-4e49-ceb4-ed01a49fda2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Write your code here\n",
        "import re\n",
        "sentence = 'The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys\\' soccer team from a flooded cave to the divisive election of President Donald Trump.\"'\n",
        "all = re.findall(r\"2...\",sentence)\n",
        "for item in all:\n",
        "  print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010\n",
            "2010\n",
            "2019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}